# -*- coding: utf-8 -*-
"""2e-5/8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JWulpRK17olSBAFTvSUQR8X8GFsh5F8-
"""

#Learning Rate = 2e-5, Batch Size = 8
import pandas as pd
import torch
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from torch.utils.data import Dataset, DataLoader
from transformers import RobertaTokenizer, RobertaForSequenceClassification
from torch.optim import AdamW
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from tqdm import tqdm
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns

# Cihaz kontrol√º
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

all_df = pd.concat([
    pd.read_csv("/content/merged_output_cleaned.csv"),
    pd.read_csv("/content/train_data_cleaned.csv"),
    pd.read_csv("/content/test_data_cleaned.csv")
]).dropna(subset=["Sentence", "Stage"]).reset_index(drop=True)

# Shuffle + encode
all_df = all_df.sample(frac=1, random_state=42).reset_index(drop=True)
label_encoder = LabelEncoder()
all_df["label"] = label_encoder.fit_transform(all_df["Stage"])

# Train/Val/Test split (%70/15/15)
train_df, temp_df = train_test_split(all_df, test_size=0.3, stratify=all_df["label"], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df["label"], random_state=42)

# Dataset sƒ±nƒ±fƒ±
class SchemaDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors="pt",
        )
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "labels": torch.tensor(self.labels[idx], dtype=torch.long),
        }

# Tokenizer ve veriler
tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
train_dataset = SchemaDataset(train_df["Sentence"].tolist(), train_df["label"].tolist(), tokenizer)
val_dataset = SchemaDataset(val_df["Sentence"].tolist(), val_df["label"].tolist(), tokenizer)
test_dataset = SchemaDataset(test_df["Sentence"].tolist(), test_df["label"].tolist(), tokenizer)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8)
test_loader = DataLoader(test_dataset, batch_size=8)

# Class weights
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_df["label"]), y=train_df["label"])
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
print("Class Weights:", class_weights.cpu().numpy())

# Model, optimizer, loss, scheduler
model = RobertaForSequenceClassification.from_pretrained("roberta-base", num_labels=len(label_encoder.classes_)).to(device)
optimizer = AdamW(model.parameters(), lr=2e-5)
scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)
loss_fn = nn.CrossEntropyLoss(weight=class_weights)

# Eƒüitim d√∂ng√ºs√º
train_accuracies, val_accuracies = [], []
train_losses, val_losses = [], []
best_val_loss = float('inf')
early_stop_counter = 0
early_stop_patience = 2

for epoch in range(10):
    model.train()
    total_loss, correct, total = 0, 0, 0
    loop = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")
    for batch in loop:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        loss = loss_fn(logits, labels)
        loss.backward()
        optimizer.step()

        preds = torch.argmax(logits, dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)
        total_loss += loss.item()
        loop.set_postfix(loss=loss.item())

    train_acc = correct / total
    train_accuracies.append(train_acc)
    train_losses.append(total_loss / len(train_loader))

    # Validation
    model.eval()
    val_loss, val_correct, val_total = 0, 0, 0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            loss = loss_fn(logits, labels)
            val_loss += loss.item()

            preds = torch.argmax(logits, dim=1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_val_loss = val_loss / len(val_loader)
    val_acc = val_correct / val_total
    val_accuracies.append(val_acc)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch+1} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {avg_val_loss:.4f}")
    scheduler.step(avg_val_loss)

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), "best_model.pt")
        early_stop_counter = 0
        print("‚úÖ Best model saved.")
    else:
        early_stop_counter += 1
        if early_stop_counter >= early_stop_patience:
            print("‚èπÔ∏è Early stopping triggered.")
            break

# Accuracy Plot
epochs = list(range(1, len(train_accuracies) + 1))

plt.figure(figsize=(8, 5))
plt.plot(epochs, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(epochs, val_accuracies, label='Validation Accuracy', marker='o')
plt.title('Accuracy per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.xticks(epochs)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("accuracy_plot_fixed.png", dpi=300)
plt.show()

# Loss Plot
epochs = list(range(1, len(train_losses) + 1))

plt.figure(figsize=(8, 5))
plt.plot(epochs, train_losses, label='Train Loss', marker='o')
plt.plot(epochs, val_losses, label='Validation Loss', marker='o')
plt.title('Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.xticks(epochs)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("loss_plot_fixed.png", dpi=300)
plt.show()

# En iyi modeli geri y√ºkle
model.load_state_dict(torch.load("best_model.pt"))
print("üîÑ Best model restored for final evaluation.")

# Test deƒüerlendirme
model.eval()
test_loss, test_preds, true_labels = 0, [], []
with torch.no_grad():
    for batch in test_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        loss = loss_fn(logits, labels)
        test_loss += loss.item()

        preds = torch.argmax(logits, dim=1)
        test_preds.extend(preds.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

avg_test_loss = test_loss / len(test_loader)
test_accuracy = np.mean(np.array(test_preds) == np.array(true_labels))
test_f1_macro = f1_score(true_labels, test_preds, average='macro')
test_f1_weighted = f1_score(true_labels, test_preds, average='weighted')

print(f"Test Loss: {avg_test_loss:.4f}")
print("Test Report:")
print(classification_report(true_labels, test_preds, labels=list(range(len(label_encoder.classes_))), target_names=label_encoder.classes_))

# Confusion matrix
cm = confusion_matrix(true_labels, test_preds)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# ==== SONU√á KAYDI & √ñZET TABLO ====
results = [{
    "Learning Rate": 2e-5,
    "Batch Size": 8,
    "Train Accuracy (Last Epoch)": train_accuracies[-1],
    "Validation Accuracy (Last Epoch)": val_accuracies[-1],
    "Validation Loss (Last Epoch)": val_losses[-1],
    "Test Accuracy": test_accuracy,
    "Test Loss": avg_test_loss,
    "F1 Score (Macro)": test_f1_macro,
    "F1 Score (Weighted)": test_f1_weighted
}]

# ==== YSQ TEST L3 ====
ysq_df = pd.read_csv("/content/ysq_data_L3.csv").dropna(subset=["Sentence", "Stage"])
ysq_df["label"] = label_encoder.transform(ysq_df["Stage"])
ysq_dataset = SchemaDataset(ysq_df["Sentence"].tolist(), ysq_df["label"].tolist(), tokenizer)
ysq_loader = DataLoader(ysq_dataset, batch_size=4)

model.eval()
ysq_preds, ysq_labels = [], []
with torch.no_grad():
    for batch in ysq_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)
        ysq_preds.extend(preds.cpu().numpy())
        ysq_labels.extend(labels.cpu().numpy())

# Accuracy & F1
ysq_accuracy = np.mean(np.array(ysq_preds) == np.array(ysq_labels))
ysq_f1_macro = f1_score(ysq_labels, ysq_preds, average='macro')
ysq_f1_weighted = f1_score(ysq_labels, ysq_preds, average='weighted')

# Classification Report
print("\nYSQ Evaluation:")
print(classification_report(ysq_labels, ysq_preds, labels=list(range(len(label_encoder.classes_))), target_names=label_encoder.classes_))

# Confusion Matrix
ysq_cm = confusion_matrix(ysq_labels, ysq_preds)
plt.figure(figsize=(12, 10))
sns.heatmap(ysq_cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.title("YSQ Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("ysq_confusion_matrix.png", dpi=300)
plt.show()

# Save to results
results[0]["YSQ Accuracy"] = ysq_accuracy
results[0]["YSQ F1 (Macro)"] = ysq_f1_macro
results[0]["YSQ F1 (Weighted)"] = ysq_f1_weighted

# Save summary table
results_df = pd.DataFrame(results)
print("\nSummary Table:")
print(results_df)
results_df.to_csv("test1_results_summary.csv", index=False)

# ==== YSQ TEST (90)====
ysq_df = pd.read_csv("/content/ysq_data_90.csv").dropna(subset=["Sentence", "Stage"])
ysq_df["label"] = label_encoder.transform(ysq_df["Stage"])
ysq_dataset = SchemaDataset(ysq_df["Sentence"].tolist(), ysq_df["label"].tolist(), tokenizer)
ysq_loader = DataLoader(ysq_dataset, batch_size=4)

model.eval()
ysq_preds, ysq_labels = [], []
with torch.no_grad():
    for batch in ysq_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)
        ysq_preds.extend(preds.cpu().numpy())
        ysq_labels.extend(labels.cpu().numpy())

# Accuracy & F1
ysq_accuracy = np.mean(np.array(ysq_preds) == np.array(ysq_labels))
ysq_f1_macro = f1_score(ysq_labels, ysq_preds, average='macro')
ysq_f1_weighted = f1_score(ysq_labels, ysq_preds, average='weighted')

# Classification Report
print("\nYSQ Evaluation:")
print(classification_report(ysq_labels, ysq_preds, labels=list(range(len(label_encoder.classes_))), target_names=label_encoder.classes_))

# Confusion Matrix
ysq_cm = confusion_matrix(ysq_labels, ysq_preds)
plt.figure(figsize=(12, 10))
sns.heatmap(ysq_cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.title("YSQ Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("ysq_confusion_matrix.png", dpi=300)
plt.show()

# Save to results
results[0]["YSQ Accuracy"] = ysq_accuracy
results[0]["YSQ F1 (Macro)"] = ysq_f1_macro
results[0]["YSQ F1 (Weighted)"] = ysq_f1_weighted

# Save summary table
results_df = pd.DataFrame(results)
print("\nSummary Table:")
print(results_df)
results_df.to_csv("test1_results_summary.csv", index=False)