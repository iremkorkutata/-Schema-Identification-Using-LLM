{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5f7d70-cc8e-4dce-a768-f7ba0bf748c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "#OpenAI API KEy\n",
    "openai.api_key = \"sk-proj-\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec778ef-9638-43ab-a18c-03c4e9009d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt(prompt_path):\n",
    "    with open(prompt_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def generate_sentences(prompt_text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON parse hatası:\", content[:300])\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feee2a69-3325-413e-b3fc-df4553c53208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schema_sentences(prompt_path, output_json_path, output_csv_path, total_needed=300, batch_size=30):\n",
    "    base_prompt = load_prompt(prompt_path)\n",
    "    collected = []\n",
    "\n",
    "    while len(collected) < total_needed:\n",
    "        needed = min(batch_size, total_needed - len(collected))\n",
    "        current_prompt = base_prompt.replace(\"Generate 30\", f\"Generate {needed}\")\n",
    "        new_sentences = generate_sentences(current_prompt)\n",
    "        collected.extend([s for s in new_sentences if isinstance(s, str)])\n",
    "        collected = list(dict.fromkeys(collected))  # Duplicate'leri temizle\n",
    "        print(f\"{prompt_path.name}: {len(collected)}/{total_needed} cümle toplandı.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    # JSON olarak kaydet\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(collected[:total_needed], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # CSV olarak da kaydet\n",
    "    with open(output_csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Sentence\"])\n",
    "        for s in collected[:total_needed]:\n",
    "            writer.writerow([s])\n",
    "\n",
    "    print(f\"Tamamlandı: {prompt_path.stem} → {total_needed} cümle kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b95ef9-3db0-45f9-bca3-97c38726ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"AB.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a176e3-7187-423e-bc72-6cc2a417f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"AS.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb79df3-69a8-447c-9cac-ec6491298436",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"DI.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f8368-9a96-4924-98bb-582160d914b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"DS.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b546f9a-5d06-4660-9a8c-8cba98592c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"ED.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecdff4-b85b-4497-add0-80b3c03176af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"EI.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810a041-c628-4564-afa1-58fc9c16d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"EM.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63610a7b-e9c3-43f1-92a8-6116acbcfbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"ET.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf566c-748d-4529-a3ae-bf48e868cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"FA.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee9bd6-59ad-4c98-8abc-197c09c30184",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"IS.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee4781-f4ad-48a7-9656-68ee14893707",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"MA.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0b3fc-8407-44e0-bca8-f50d40035cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"NP.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce4156-87ef-4380-9951-8507e116b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"PU.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5947c-b470-4f15-a503-a2c508d7c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"SB.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06c56f-c4f1-42e3-b472-b07c29cafb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"SI.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8477e-806b-468c-8c88-8f00a9c62af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"SS.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9cb52-ecfa-4539-b3ec-e45877251e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"US.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97535f74-6978-43e9-9eb7-f13a436073ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"outputs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"VH.txt\"):\n",
    "    name = prompt_file.stem\n",
    "    json_path = output_folder / f\"{name}.json\"\n",
    "    csv_path = output_folder / f\"{name}.csv\"\n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c407b504-b6aa-46ec-b166-820b513a9e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birleştirme tamamlandı: 5400 cümle `merged_output.csv` dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "merged_rows = []\n",
    "\n",
    "for csv_file in output_dir.glob(\"*.csv\"):\n",
    "    schema_name = csv_file.stem.upper().replace(\"_\", \" \")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.insert(0, \"Stage\", schema_name)  # İlk sütuna Stage ekle\n",
    "    merged_rows.append(df)\n",
    "\n",
    "merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "merged_df.to_csv(\"merged_output.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Birleştirme tamamlandı: {len(merged_df)} cümle `merged_output.csv` dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58fbf6e5-7f75-4a7b-9655-44644fb073f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning schema: AB (300 sentences)\n",
      "Cleaning schema: AS (300 sentences)\n",
      "Cleaning schema: DI (300 sentences)\n",
      "Cleaning schema: DS (300 sentences)\n",
      "Cleaning schema: ED (300 sentences)\n",
      "Cleaning schema: EI (300 sentences)\n",
      "Cleaning schema: EM (300 sentences)\n",
      "Cleaning schema: ET (300 sentences)\n",
      "Cleaning schema: FA (300 sentences)\n",
      "Cleaning schema: IS (300 sentences)\n",
      "Cleaning schema: MA (300 sentences)\n",
      "Cleaning schema: NP (300 sentences)\n",
      "Cleaning schema: PU (300 sentences)\n",
      "Cleaning schema: SB (300 sentences)\n",
      "Cleaning schema: SI (300 sentences)\n",
      "Cleaning schema: SS (300 sentences)\n",
      "Cleaning schema: US (300 sentences)\n",
      "Cleaning schema: VH (300 sentences)\n",
      "Cleaned file saved as 'merged_output_cleaned.csv' with 4668 rows.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "import openai\n",
    "from collections import defaultdict\n",
    "\n",
    "openai.api_key = \"sk-proj-\"\n",
    "\n",
    "\n",
    "# 1. Anlamsız veya çok kısa cümleleri filtrele\n",
    "def is_sentence_meaningful(sentence):\n",
    "    if len(sentence.split()) < 4:\n",
    "        return False\n",
    "    vague_patterns = [\n",
    "        r\"\\b(i'?m bad|i am bad|i'?m worthless|i'?m a nobody|there'?s something wrong with me|i always mess up)\\b\",\n",
    "        r\"\\b(nothing ever works|i hate myself|everything is my fault)\\b\"\n",
    "    ]\n",
    "    for pattern in vague_patterns:\n",
    "        if re.search(pattern, sentence.lower()):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# 2. Çok benzer cümleleri eleyerek sadece farklı olanları tut\n",
    "def is_similar(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold\n",
    "\n",
    "def remove_duplicates(sentences):\n",
    "    unique = []\n",
    "    for s in sentences:\n",
    "        if all(not is_similar(s, u) for u in unique):\n",
    "            unique.append(s)\n",
    "    return unique\n",
    "\n",
    "# 3. (Opsiyonel) LLM yardımıyla açık ve anlamlı cümleleri seç\n",
    "def gpt_filter_sentences(schema, description, sentences):\n",
    "    prompt = (\n",
    "        f\"You are helping clean a psychological dataset.\\n\\n\"\n",
    "        f\"Schema: {schema}\\n\"\n",
    "        f\"Description: {description}\\n\\n\"\n",
    "        f\"Here is a list of first-person sentences someone might say in therapy. \"\n",
    "        f\"Please return only the sentences that clearly and emotionally express the schema (not vague, overly general, or repetitive).\\n\\n\"\n",
    "        f\"Sentences:\\n\" +\n",
    "        \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(sentences)) +\n",
    "        \"\\n\\nReturn only the numbers of the valid sentences in a JSON list format like this: [1, 3, 5]\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a psycholinguistic data filter.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    valid_ids = json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    return [sentences[i-1] for i in valid_ids]\n",
    "\n",
    "# 4. Ana temizleme işlemi\n",
    "def clean_schema_sentences(input_csv, output_csv, schema_info, use_llm=False):\n",
    "    # Cümleleri schema'ya göre grupla\n",
    "    schema_sentences = defaultdict(list)\n",
    "    with open(input_csv, newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            schema_sentences[row[\"Stage\"]].append(row[\"Sentence\"])\n",
    "\n",
    "    cleaned_rows = []\n",
    "\n",
    "    for schema, sentences in schema_sentences.items():\n",
    "        print(f\"Cleaning schema: {schema} ({len(sentences)} sentences)\")\n",
    "        \n",
    "        # Anlamsız cümleleri çıkar\n",
    "        filtered = [s for s in sentences if is_sentence_meaningful(s)]\n",
    "\n",
    "        # Tekrarlı (çok benzer) cümleleri çıkar\n",
    "        deduped = remove_duplicates(filtered)\n",
    "\n",
    "        # Opsiyonel: LLM ile içerik doğruluğu kontrolü\n",
    "        if use_llm and schema in schema_info:\n",
    "            description = schema_info[schema]\n",
    "            deduped = gpt_filter_sentences(schema, description, deduped)\n",
    "\n",
    "        # Kalan temiz cümleleri ekle\n",
    "        for s in deduped:\n",
    "            cleaned_rows.append([schema, s])\n",
    "\n",
    "    # Yeni temiz CSV dosyasını yaz\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Stage\", \"Sentence\"])\n",
    "        writer.writerows(cleaned_rows)\n",
    "\n",
    "    print(f\"Cleaned file saved as '{output_csv}' with {len(cleaned_rows)} rows.\")\n",
    "\n",
    "# Şema açıklamalarını buraya ekleyin (daha önceki JSON gibi)\n",
    "schema_info = {\n",
    "    \"ABANDONMENT / INSTABILITY (AB)\": \"The perceived instability or unreliability of those available for support and connection. Involves the sense that significant others will not be able to continue providing emotional support, connection, strength, or practical protection because they are emotionally unstable and unpredictable (e.g., angry outbursts), unreliable, or erratically present; because they will die imminently; or because they will abandon the patient in favor of someone better.\",\n",
    "    \"MISTRUST / ABUSE (MA)\": \"The expectation that others will hurt, abuse, humiliate, cheat, lie, manipulate, or take advantage. Usually involves the perception that the harm is intentional or the result of unjustified and extreme negligence. May include the sense that one always ends up being cheated relative to others or 'getting the short end of the stick.'\",\n",
    "    \"EMOTIONAL DEPRIVATION (ED)\": \"Expectation that one's desire for a normal degree of emotional support will not be adequately met by others. The three major forms of deprivation are: A. Deprivation of Nurturance: Absence of attention, affection, warmth, or companionship. B. Deprivation of Empathy: Absence of understanding, listening, self-disclosure, or mutual sharing of feelings from others. C. Deprivation of Protection: Absence of strength, direction, or guidance from others.\",\n",
    "    \"DEFECTIVENESS / SHAME (DS)\": \"The feeling that one is defective, bad, unwanted, inferior, or invalid in important respects; or that one would be unlovable to significant others if exposed. May involve hypersensitivity to criticism, rejection, and blame; self-consciousness, comparisons, and insecurity around others; or a sense of shame regarding one's perceived flaws.\",\n",
    "    \"SOCIAL ISOLATION / ALIENATION (SI)\": \"The feeling that one is isolated from the rest of the world, different from other people, and/or not part of any group or community.\",\n",
    "    \"DEPENDENCE / INCOMPETENCE (DI)\": \"Belief that one is unable to handle one's everyday responsibilities in a competent manner, without considerable help from others. Often presents as helplessness.\",\n",
    "    \"VULNERABILITY TO HARM OR ILLNESS (VH)\": \"Exaggerated fear that imminent catastrophe will strike at any time and that one will be unable to prevent it. Fears include medical, emotional, or external catastrophes (e.g., heart attacks, going crazy, or natural disasters).\",\n",
    "    \"ENMESHMENT / UNDEVELOPED SELF (EM)\": \"Excessive emotional involvement and closeness with significant others (often parents), at the expense of individuation or normal social development. May include feelings of being smothered or fused with others and an insufficient individual identity.\",\n",
    "    \"FAILURE (FA)\": \"The belief that one has failed, will inevitably fail, or is fundamentally inadequate relative to peers, especially in achievement areas. Often involves feelings of being inept or untalented.\",\n",
    "    \"ENTITLEMENT / GRANDIOSITY (ET)\": \"The belief that one is superior to others, entitled to special rights or privileges, and not bound by the rules that govern normal social interaction. May involve excessive competitiveness or domination.\",\n",
    "    \"INSUFFICIENT SELF-CONTROL / SELF-DISCIPLINE (IS)\": \"Difficulty or refusal to exercise sufficient self-control or frustration tolerance to achieve personal goals. In milder form, it shows as an excessive emphasis on avoiding discomfort.\",\n",
    "    \"SUBJUGATION (SB)\": \"Excessive surrendering of control to others to avoid anger, retaliation, or abandonment. Involves suppressing personal needs and emotions.\",\n",
    "    \"SELF-SACRIFICE (SS)\": \"Excessive focus on meeting the needs of others at the expense of one’s own gratification, often to prevent causing pain or avoid guilt.\",\n",
    "    \"APPROVAL-SEEKING / RECOGNITION-SEEKING (AS)\": \"Excessive emphasis on gaining approval, recognition, or attention from others at the expense of developing a true sense of self.\",\n",
    "    \"NEGATIVITY / PESSIMISM (NP)\": \"A pervasive focus on the negative aspects of life while minimizing or neglecting the positive. Includes chronic worry and fear of mistakes.\",\n",
    "    \"EMOTIONAL INHIBITION (EI)\": \"The excessive inhibition of spontaneous actions, feelings, or communication—usually to avoid disapproval, shame, or losing control of impulses.\",\n",
    "    \"UNRELENTING STANDARDS / HYPERCRITICALNESS (US)\": \"The belief that one must meet very high internalized standards to avoid criticism, resulting in pressure, self-criticism, and difficulty relaxing.\",\n",
    "    \"PUNITIVENESS (PU)\": \"The belief that people should be harshly punished for mistakes. Often involves being intolerant, punitive, and impatient with oneself or others.\"\n",
    "}\n",
    "\n",
    "# Fonksiyonu çalıştır\n",
    "clean_schema_sentences(\n",
    "    input_csv=\"merged_output.csv\",\n",
    "    output_csv=\"merged_output_cleaned.csv\",\n",
    "    schema_info=schema_info,\n",
    "    use_llm=True  #  GPT-4 ile cümle filtresi \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63836916-8fa0-4e3f-9687-06eefcd94a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
