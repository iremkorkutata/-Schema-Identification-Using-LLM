{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0eb8364-f3ce-4a64-a590-b627bd065bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "#OpenAI API KEy\n",
    "openai.api_key = \"sk-proj-\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01cc246-8731-438e-9a8a-6bb5a133ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt(prompt_path):\n",
    "    with open(prompt_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def generate_sentences(prompt_text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON parse hatası:\", content[:20])\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79de17d-4866-43f6-acc5-9ff4d129e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schema_sentences(prompt_path, output_json_path, output_csv_path, total_needed=20, batch_size=10):\n",
    "    base_prompt = load_prompt(prompt_path)\n",
    "    collected = []\n",
    "\n",
    "    while len(collected) < total_needed:\n",
    "        needed = min(batch_size, total_needed - len(collected))\n",
    "        current_prompt = base_prompt.replace(\"Generate 30\", f\"Generate {needed}\")\n",
    "        new_sentences = generate_sentences(current_prompt)\n",
    "        collected.extend([s for s in new_sentences if isinstance(s, str)])\n",
    "        collected = list(dict.fromkeys(collected))  # Duplicate'leri temizle\n",
    "        print(f\"{prompt_path.name}: {len(collected)}/{total_needed} cümle toplandı.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    # JSON olarak kaydet\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(collected[:total_needed], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # CSV olarak da kaydet\n",
    "    with open(output_csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Sentence\"])\n",
    "        for s in collected[:total_needed]:\n",
    "            writer.writerow([s])\n",
    "\n",
    "    print(f\"Tamamlandı: {prompt_path.stem} → {total_needed} cümle kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc1c8e6-bf84-4e91-b225-ca8d38f44c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB.txt: 10/20 cümle toplandı.\n",
      "AB.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: AB → 20 cümle kaydedildi.\n",
      "AS.txt: 10/20 cümle toplandı.\n",
      "AS.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: AS → 20 cümle kaydedildi.\n",
      "DI.txt: 10/20 cümle toplandı.\n",
      "DI.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: DI → 20 cümle kaydedildi.\n",
      "DS.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I constantly feel\n",
      "DS.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I constantly feel\n",
      "DS.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I constantly feel\n",
      "DS.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I constantly feel\n",
      "DS.txt: 10/20 cümle toplandı.\n",
      "DS.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: DS → 20 cümle kaydedildi.\n",
      "JSON parse hatası: [\n",
      "\"I feel like no on\n",
      "ED.txt: 0/20 cümle toplandı.\n",
      "ED.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I feel so alone, \n",
      "ED.txt: 10/20 cümle toplandı.\n",
      "ED.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: ED → 20 cümle kaydedildi.\n",
      "EI.txt: 10/20 cümle toplandı.\n",
      "EI.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: EI → 20 cümle kaydedildi.\n",
      "EM.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I feel suffocated\n",
      "EM.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I feel like I can\n",
      "EM.txt: 10/20 cümle toplandı.\n",
      "EM.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: EM → 20 cümle kaydedildi.\n",
      "JSON parse hatası: [\n",
      "\"I deserve only th\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I am destined for\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve special\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve to alwa\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve to be a\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve only th\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve to be t\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I am destined for\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve only th\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I am the best the\n",
      "ET.txt: 0/20 cümle toplandı.\n",
      "ET.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I deserve special\n",
      "ET.txt: 10/20 cümle toplandı.\n",
      "ET.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: ET → 20 cümle kaydedildi.\n",
      "JSON parse hatası: [\n",
      "\"I always seem to \n",
      "FA.txt: 0/20 cümle toplandı.\n",
      "FA.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I always fall sho\n",
      "FA.txt: 10/20 cümle toplandı.\n",
      "FA.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: FA → 20 cümle kaydedildi.\n",
      "IS.txt: 10/20 cümle toplandı.\n",
      "IS.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: IS → 20 cümle kaydedildi.\n",
      "MA.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I always feel lik\n",
      "MA.txt: 10/20 cümle toplandı.\n",
      "MA.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: MA → 20 cümle kaydedildi.\n",
      "NP.txt: 10/20 cümle toplandı.\n",
      "NP.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: NP → 20 cümle kaydedildi.\n",
      "JSON parse hatası: [\n",
      "\"I deserve to suff\n",
      "PU.txt: 0/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I believe that mi\n",
      "PU.txt: 0/20 cümle toplandı.\n",
      "PU.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I believe in hold\n",
      "PU.txt: 10/20 cümle toplandı.\n",
      "JSON parse hatası: [\n",
      "\"I believe in stri\n",
      "PU.txt: 10/20 cümle toplandı.\n",
      "PU.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: PU → 20 cümle kaydedildi.\n",
      "SB.txt: 10/20 cümle toplandı.\n",
      "SB.txt: 19/20 cümle toplandı.\n",
      "SB.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: SB → 20 cümle kaydedildi.\n",
      "JSON parse hatası: [\n",
      "\"I feel like a str\n",
      "SI.txt: 0/20 cümle toplandı.\n",
      "SI.txt: 10/20 cümle toplandı.\n",
      "SI.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: SI → 20 cümle kaydedildi.\n",
      "SS.txt: 10/20 cümle toplandı.\n",
      "SS.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: SS → 20 cümle kaydedildi.\n",
      "US.txt: 10/20 cümle toplandı.\n",
      "US.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: US → 20 cümle kaydedildi.\n",
      "VH.txt: 10/20 cümle toplandı.\n",
      "VH.txt: 20/20 cümle toplandı.\n",
      "Tamamlandı: VH → 20 cümle kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "prompt_folder = Path(\"prompts\")\n",
    "output_folder = Path(\"evaluation\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "for prompt_file in prompt_folder.glob(\"*.txt\"):  \n",
    "    name = prompt_file.stem \n",
    "    json_path = output_folder / f\"{name}.json\"  \n",
    "    csv_path = output_folder / f\"{name}.csv\" \n",
    "    generate_schema_sentences(prompt_file, json_path, csv_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e070bf8c-fe52-42d6-8c1d-9401fdfbd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birleştirme tamamlandı: 360 cümle `evaluation_data.csv` dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = Path(\"evaluation\")\n",
    "merged_rows = []\n",
    "\n",
    "for csv_file in output_dir.glob(\"*.csv\"):\n",
    "    schema_name = csv_file.stem.upper().replace(\"_\", \" \")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.insert(0, \"Stage\", schema_name)  # İlk sütuna Stage ekle\n",
    "    merged_rows.append(df)\n",
    "\n",
    "merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "merged_df.to_csv(\"evaluation_data.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Birleştirme tamamlandı: {len(merged_df)} cümle `evaluation_data.csv` dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8da9d-4776-4db0-966c-f1b62e16846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Boş liste oluştur\n",
    "data = []\n",
    "\n",
    "# TXT dosyasını satır satır oku, ilk satırı atla\n",
    "with open(\"young_sentence.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i == 0:\n",
    "            continue  # İlk satırı atla\n",
    "        parts = line.strip().split(\",\", 1)\n",
    "        if len(parts) == 2:\n",
    "            stage, sentence = parts\n",
    "            data.append({\"Stage\": stage.strip(), \"Sentence\": sentence.strip()})\n",
    "\n",
    "# DataFrame oluştur\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV'ye kaydet\n",
    "df.to_csv(\"stage_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef3a6a-86dd-441c-b0d2-3fdd6d25929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyaları oku\n",
    "df1 = pd.read_csv(\"evaluation_data.csv\")   # İlk CSV\n",
    "df2 = pd.read_csv(\"stage_sentence.csv\")    # İkinci CSV\n",
    "\n",
    "# Gerekirse sütun adlarını kontrol et ve eşleştir\n",
    "df2 = df2[[\"Stage\", \"Sentence\"]]           # Sadece gerekli sütunları al\n",
    "\n",
    "# Satır bazlı birleştirme (alt alta)\n",
    "merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "# Sonuç dosyasını kaydet\n",
    "merged_df.to_csv(\"evaluation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
